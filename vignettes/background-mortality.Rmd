---
title: "Background mortality"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Background mortality}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This is the second in a series of vignettes illustrating methods for evaluating the fit and efficiency of three state oncology cost-effectiveness model structures, as described in an accompanying journal article.[1] The package is heavily dependent on [flexsurv](https://cran.r-project.org/package=flexsurv)).[2]

It is being rewritten.

After fitting models, as described in `vignette("example")`, estimates of restricted mean durations in health states can be calculated after constraining for background mortality from a given life table.

## What does constraining for background mortality mean?

### Approach 1 - Constraining only the survival function

This background mortality is assumed to limit the survival function as follows.

$$
S_{adjusted}(t) = \min \left[ S_{unadjusted}(t), S_{background}(t) \right]
$$

This is a simple approach, and has been used at least one NICE technology appraisal: "Patient longevity is always the lesser of values generated from the disease-specific survival curve (after adjustment for treatment and functional status) and the survival curve for the general population according to age and sex." [3] However, this approach does not ensure that the hazard is at least as great as the hazard of background mortality.

### Approach 2 - Constraining the hazard function

A more reasonable adjustment would be that the hazard of background mortality acts as a constraint to the unadjusted hazard.[4]

$$
h_{adjusted}(t) = \max \left[ h_{unadjusted}(t), h_{background}(t) \right]
\implies S_{adjusted}(t) = \exp \left[ - \int_0^t h_{adjusted}(u) du \right]
$$
In either case, we must assume that the original dataset was NOT subject to background mortality. Although unlikely to be true, this is a common, pragmatic assumption in cost-effectiveness models as long as background mortality is relatively insignificant during trial follow-up.

### Approach 3 - Modeling excess hazard in the original dataset

The above approaches work by adjusting extrapolations made from models fitted to data assumed to be not subject to background mortality. If - as is likely - the population in the dataset were in fact subject to background mortality, then it would be better to model that dataset using excess hazard methods rather than to seek to make adjustments to extrapolations after the fact. Further discussion of survival extrapolation incorporating general population mortality is provided by Sweeting et al.[4]

## Deriving restricted mean duration estimates under Approach 1

Following the notation in the journal article supporting thispackage, where membership probabilities at time $t$ from baseline are defined in terms of survival and hazard functions of $t$ [1].

### Background mortality survival and hazard functions

Our lifetable gives us decreasing $l_x$ values at points between $t=0, ..., t_{max}$, with $l_{t_{max}}=0$. Let us define the background mortality survival function as follows.

$$
S_{gen}(t) = 1 - R \left(1 - \frac{l_{x_0 + t}}{l_{x_0}} \right)
$$

where $x_0$ is the mean age of the study population at baseline, and
$l_x$ is an appropriate lifetable.

We can also derive the average background mortality hazard for $t$ in the range $[t_1, t_2)$.

$$
h_{gen}(t) = \frac{\log[S_{gen}(t_1)] - \log[S_{gen}(t_2)]}{t_2 - t_1}
$$

### Partitioned Survival Model (PSM)

The restricted mean time in the PF state and time alive are integrals over the time horizon, $T$, of the survival functions of PFS and OS. In both cases, the hazard functions must be constrained to be at least as great as the hazard for background mortality. The hazard for the time in PF and time alive (OS) are as follows.

$$
h^{adj}_{OS}(t) = \max \left[h_{gen}(t), h_{OS}(t) \right] \\
h^{adj}_{PFS}(t) = h_{PFS}(t) - h_{OS}(t) + h^{adj}_{OS}(t)
$$

The mean time in PF and alive are integrals of the survival functions, which are related to integrals of the adjusted hazard functions above.

### State Transition Models

Formulas for the mean time in PF and OS are shown in the accompanying article in respect of hazard and survival functions for TTP, PPD and PPS endpoints, where PPS is a function of time from baseline in a Clock Forward model and time from progression in a Clock Reset model.

Adjusting for background mortality requires adjusting the hazard (and equivalently survival) functions of endpoints relating to mortality, PPD and PPS. This is straightforward for PPD:

$$
h_{adj}_{PPD}(t) = \max left[h_{gen}(t), h_{PPD}(t) \right]
$$
But it is more complex


$$
E[PF, STM_{CF}] = \int_0^T S_{TTP}(u) \cdot \min \left[ S_{PPD}(u), S_{gen}(u) \right] du
$$
The mean time in PD is rather more complicated. Note that the PPS survival differs between the clock forward and clock reset model structures.

$$
E[PD, STM] = \int_0^T \int_0^t \min \left[ S_{PPD}(u), S_{gen}(u) \right] \cdot S_{TTP}(u) \cdot h_{TTP}(u) \cdot \min \left[ S_{PPS}(u, t), \frac{S_{gen}(t)}{S_{gen}(u)} \right] du dt
$$
The observant statistician would note $S_{TTP}(u) \cdot h_{TTP}(u) = f_{TTP}(u)$, the density function. The time alive is then the sum of these quantities.

$$
E[OS, STM] = E[PF, STM] + E[PD, STM]
$$

### Discounting

Health economic models such as cost-effectiveness models usually evaluate quantities of interest in (net) present value terms, after applying discounting. This can be readily included in formulae above by including a discounting factor in the integrals.

Suppose a discount rate $i$\% applies over unit time. Then the discounting factor at time $t$ is $v(t;i)=(1+i)^{-t}$. Note that $v(t;i=0)=1$.

### Programming implications

The calculation of restricted mean durations in *psm3mkv* default to assume no life table constraints or discounting. However, when a lifetable is specified, then $S_{gen}(t)$ and $h_{gen}(t)$ are specified and constrain the estimated means as indicated. When a discount rate is specified, then the mean estimates reflect this also.

## Demonstration

### Initializing

First we load the packages we need - all of which are suggested for or imported to *psm3mkv*. With thanks again to @vbaliga for [this helpful code](https://vbaliga.github.io/posts/2019-04-28-verify-that-r-packages-are-installed-and-loaded/)).

```{r packages, message=FALSE}
# Install psm3mkv version 0.2 from github
require("remotes")
remotes::install_github("Merck/psm3mkv",
                        ref="v0.2",
                        build_vignettes=TRUE)

# First specify the packages of interest
packages = c("psm3mkv", "dplyr", "flexsurv", "HMDHFDplus", "remotes")

# Now load or install & load all
package.check <- lapply(
  packages,
  FUN = function(x) {
    if (!require(x, character.only = TRUE)) {
      install.packages(x, dependencies = TRUE)
      library(x, character.only = TRUE)
    }
  }
)
```

### Creating the life table

In order to apply constraints to background mortality, we need some background mortality data, in the form of a lifetable. We can take this from the Human Mortality Database using the *HMDHFDplus* package mentioned above (with thanks to Robert Hettle for the recommendation). The lifetable will need to start from an assumed age at baseline. Lifetables are constructed by time in years.

```{r ltable1, eval=FALSE}
# Assumed population age at baseline (time=0)
baseage <- 51.0

# Mortality data - England & Wales, Female, 2019
mort <- HMDHFDplus::readHMDweb(CNTRY="GBRTENW",
                        item="fltper_1x1",
                        username="",
                        password=""
                        ) |>
              filter(Year==2019) |>
              select(Age, lx, dx) |>
              mutate(Timey = ceiling(Age-baseage)) |>
              filter(Timey>=0)

# The table needs to end with lx=0
mort <- dplyr::add_row(mort, Age=111, lx=0, Timey=60)
```

You will see that the above code cannot run without a login for the Human Mortality Database (www.mortality.org). Alternatively, we could just make up a mortality table.

```{r ltable2}
mort <- tibble::tibble(
  Timey = 0:30,
  lx = 10000 * exp(-0.03 * Timey^1.1),
  dx = lx - dplyr::lead(lx),
  qx = dx/lx
  )
```

However we do it, once we have the mortality data, we can apply the SMR ($R$) and derive a lifetable from time zero as required.

```{r ltable3}
# Assumed Standardized Mortality Ratio
SMR <- 2

# Recalculate the lifetable with the SMR applied
mort$adjlx <- mort$lx
for (i in 2:length(mort$lx)) {
  mort$adjlx[i] <- mort$adjlx[i-1] * (1 - SMR * mort$qx[i-1])
}

# Ensure lx>=0
mort$adjlx[mort$adjlx<0] <- 0

# Create and view lifetable
ltable <- tibble::tibble(lttime=mort$Timey, lx=mort$adjlx)
head(ltable)
```

Next we get some patient-level data and fit the PSM and STMs. So far, we are closely following `vignette("example")`. Time is assumed to be recorded in the patient-level data in weeks, with approximately `r round(365.25/7,2)` weeks per year.

```{r datafit}
# Get some data
bosonc <- create_dummydata("flexbosms")

# We'll make the durations a lot longer
# so that they will be definitely constrained by the lifetable
bosonc <- bosonc |>
  dplyr:: mutate(
    pfs.durn = 20 * pfs.durn,
    os.durn = 20 * os.durn,
    ttp.durn = 20 * ttp.durn
  )

# Fit Royston Parmar splines models to each endpoint
allfits <- fit_ends_mods_par(bosonc)

# Pick out best distributions according to min AIC
fit.ppd <- find_bestfit_par(allfits$ppd, "aic")
fit.ttp <- find_bestfit_par(allfits$ttp, "aic")
fit.pfs <- find_bestfit_par(allfits$pfs, "aic")
fit.os <- find_bestfit_par(allfits$os, "aic")
fit.pps_cf <- find_bestfit_par(allfits$pps_cf, "aic")
fit.pps_cr <- find_bestfit_par(allfits$pps_cr, "aic")

# Bring together our preferred fits for each endpoint in a list
params <- list(ppd = fit.ppd$fit,
               ttp = fit.ttp$fit,
               pfs = fit.pfs$fit,
               os = fit.os$fit,
               pps_cf = fit.pps_cf$fit,
               pps_cr = fit.pps_cr$fit
               )
```

### Making the projections

We are skipping over any internal or external validation for the purposes of this vignette, and jump instead straight to making the survival projections.

First we derive a projection without lifetable constraints over a 10 year time horizon.

```{r proj1}
# Set time horizon
thoz <- 10

# Run the calculations
proj1 <- calc_allrmds(bosonc, dpam=params, Ty=thoz)

# Present the results
res1 <- proj1$results |> dplyr::mutate(lxadj="no", disc=0)
res1 |> dplyr::mutate(
  dplyr::across(c(pf, pd, os), ~ tibble::num(.x, digits = 1)))
```

Then we derive a projection with lifetable constraints (according to Approach 1) over the same time horizon.

```{r proj2}
# Run the calculation
proj2 <- calc_allrmds(bosonc, dpam=params, Ty=thoz, lifetable=ltable)

# Present the results
res2 <- proj2$results |> dplyr::mutate(lxadj="yes", disc=0)
res2 |> dplyr::mutate(
  dplyr::across(c(pf, pd, os), ~ tibble::num(.x, digits = 1)))
```

The State Transition Model Clock Reset (STM-CR) estimate of mean time alive has reduced by `r round(res1$os[3]-res2$os[3],1)` weeks for example, from `r round(res1$os[3],1)` to `r round(res2$os[3],1)` weeks.

### Discounting

Let us compare the effects of the lifetable constraint with the effect of discounting. First we run a model with discounting at 3.5\% per year, but no lifetable constraint.

```{r proj3}
# Run the calculations
proj3 <- calc_allrmds(bosonc, dpam=params, Ty=thoz, discrate=0.035)

# Present the results
res3 <- proj3$results |>
  dplyr::mutate(lxadj="no", disc=3.5)
res3 |> dplyr::mutate(
    dplyr::across(c(pf, pd, os), ~ tibble::num(.x, digits = 1)))
```

Discounting alone reduces the STM-CR estimate of mean time alive by `r round(res1$os[3]-res3$os[3],1)` weeks for example, from `r round(res1$os[3],1)` to `r round(res3$os[3],1)` weeks.

Applying a lifetable constraint and discounting at 3.5\% per year produces our final model for this vignette.

```{r proj4}
# Run the calculations
proj4 <- calc_allrmds(bosonc, dpam=params, Ty=thoz, lifetable=ltable, discrate=0.035)

# Present the results
res4 <- proj4$results |> dplyr::mutate(lxadj="yes", disc=3.5)
res4 |> dplyr::mutate(
    dplyr::across(c(pf, pd, os), ~ tibble::num(.x, digits = 1)))
```

The final STM-CR estimate of mean time alive, with both a lifetable constraint and discounting at 3.5\% per year is `r round(res4$os[3],1)` weeks.

A summary of the STM-CR estimates of mean time in PF is given in the table below.

|Model | Mean time in PF (weeks) | Change (weeks) | Mean time alive (weeks) | Change (weeks) |
|:---------------|:----------|:----------|:----------|:----------|
| No lifetable constraint, no discounting | `r round(res1$pf[3],1)` | - | `r round(res1$os[3],1)` | - |
| With lifetable constraint, no discounting | `r round(res2$pf[3],1)` | `r round(res2$pf[3]-res1$pf[3],1)` | `r round(res2$os[3],1)` | `r round(res2$os[3]-res1$os[3],1)` |
| No lifetable constraint, discounting at 3.5\% pa | `r round(res3$pf[3],1)` | `r round(res3$pf[3]-res1$pf[3],1)` | `r round(res3$os[3],1)` | `r round(res3$os[3]-res1$os[3],1)` |
| With lifetable constraint, discounting at 3.5\% pa | `r round(res4$pf[3],1)` | `r round(res4$pf[3]-res1$pf[3],1)` | `r round(res4$os[3],1)` | `r round(res4$os[3]-res1$os[3],1)` |

### Discounting

Health economic models such as cost-effectiveness models usually evaluate quantities of interest in (net) present value terms, after applying discounting. This can be readily included in formulae above by including a discounting factor in the integrals.

Suppose a discount rate $i$\% applies over unit time. Then the discounting factor at time $t$ is $v(t;i)=(1+i)^{-t}$. Note that $v(t;i=0)=1$.

### Programming implications

The calculation of restricted mean durations in *psm3mkv* default to assume no life table constraints or discounting. However, when a lifetable is specified, then $S_{gen}(t)$ and $h_{gen}(t)$ are specified and constrain the estimated means as indicated. When a discount rate is specified, then the mean estimates reflect this also.


### Creating the life table

In order to apply constraints to background mortality, we need some background mortality data, in the form of a lifetable. We can take this from the Human Mortality Database using the *HMDHFDplus* package mentioned above (with thanks to Robert Hettle for the recommendation). The lifetable will need to start from an assumed age at baseline. Lifetables are constructed by time in years.

```{r ltable1, eval=FALSE}
# Assumed population age at baseline (time=0)
baseage <- 51.0

# Mortality data - England & Wales, Female, 2019
mort <- HMDHFDplus::readHMDweb(CNTRY="GBRTENW",
                        item="fltper_1x1",
                        username="",
                        password=""
                        ) |>
              filter(Year==2019) |>
              select(Age, lx, dx) |>
              mutate(Timey = ceiling(Age-baseage)) |>
              filter(Timey>=0)

# The table needs to end with lx=0
mort <- dplyr::add_row(mort, Age=111, lx=0, Timey=60)
```

You will see that the above code cannot run without a login for the Human Mortality Database (www.mortality.org). Alternatively, we could just make up a mortality table.

```{r ltable2}
mort <- tibble::tibble(
  Timey = 0:30,
  lx = 10000 * exp(-0.03 * Timey^1.1),
  dx = lx - dplyr::lead(lx),
  qx = dx/lx
  )
```

However we do it, once we have the mortality data, we can apply the SMR ($R$) and derive a lifetable from time zero as required.

```{r ltable3}
# Assumed Standardized Mortality Ratio
SMR <- 2

# Recalculate the lifetable with the SMR applied
mort$adjlx <- mort$lx
for (i in 2:length(mort$lx)) {
  mort$adjlx[i] <- mort$adjlx[i-1] * (1 - SMR * mort$qx[i-1])
}

# Ensure lx>=0
mort$adjlx[mort$adjlx<0] <- 0

# Create and view lifetable
ltable <- tibble::tibble(lttime=mort$Timey, lx=mort$adjlx)
head(ltable)
```

## References

1. Muston D. Informing structural assumptions for three state oncology cost-effectiveness models through model efficiency and fit. In review.

2. Jackson C, Metcalfe P, Amdahl J, Warkentin MT, Sweeting M, Kunzmann K. flexsurv: Flexible Parametric Survival and Multi-State Models. Available at: https://cran.r-project.org/package=flexsurv.

3. National Institute for Health and Care Excellence. Avalglucosidase alfa for treating Pompe disease. Technology appraisal guidance [TA821]. August 24, 2022. Available from: [https://www.nice.org.uk/guidance/ta821/documents/committee-papers](https://www.nice.org.uk/guidance/ta821/documents/committee-papers)

4. Sweeting et al. Survival Extrapolation Incorporating General Population Mortality Using Excess Hazard and Cure Models: A Tutorial. Med Decis Making 2023 Aug;43(6):737-748. [DOI: 10.1177/0272989X231184247](https://doi.org/10.1177/0272989X231184247)
